<html lang="en"><head>
    <meta charset="UTF-8">
    <title>Research</title>
    <link rel="icon" type="image/x-icon" href="https://avatars1.githubusercontent.com/u/10704714?s=460&v=4"/>
<style id="system" type="text/css">body{}</style><style id="custom" type="text/css">html { font-size: 100%; overflow-y: scroll; -webkit-text-size-adjust: 100%; -ms-text-size-adjust: 100%; }

body{
color:#444;
font-family:Georgia, Palatino, 'Palatino Linotype', Times, 'Times New Roman', serif;
font-size:12px;
line-height:1.5em;
padding:1em;
margin:auto;
max-width:65em;
background:#fefefe;
}

a{ color: #0645ad; text-decoration:none;}
a:visited{ color: #0b0080; }
a:hover{ color: #06e; }
a:active{ color:#faa700; }
a:focus{ outline: thin dotted; }
a:hover, a:active{ outline: 0; }

::-moz-selection{background:rgba(255,255,0,0.3);color:#000}
::selection{background:rgba(255,255,0,0.3);color:#000}

a::-moz-selection{background:rgba(255,255,0,0.3);color:#0645ad}
a::selection{background:rgba(255,255,0,0.3);color:#0645ad}

p{
margin:1em 0;
}

img{
max-width:100%;
}

h1,h2,h3,h4,h5,h6{
font-weight:normal;
color:#111;
line-height:1em;
}
h4,h5,h6{ font-weight: bold; }
h1{ font-size:2.5em; }
h2{ font-size:2em; }
h3{ font-size:1.5em; }
h4{ font-size:1.2em; }
h5{ font-size:1em; }
h6{ font-size:0.9em; }

blockquote{
color:#666666;
margin:0;
padding-left: 3em;
border-left: 0.5em #EEE solid;
}
hr { display: block; height: 2px; border: 0; border-top: 1px solid #aaa;border-bottom: 1px solid #eee; margin: 1em 0; padding: 0; }
pre, code, kbd, samp { color: #000; font-family: monospace, monospace; _font-family: 'courier new', monospace; font-size: 0.98em; }
pre { white-space: pre; white-space: pre-wrap; word-wrap: break-word; }

b, strong { font-weight: bold; }

dfn { font-style: italic; }

ins { background: #ff9; color: #000; text-decoration: none; }

mark { background: #ff0; color: #000; font-style: italic; font-weight: bold; }

sub, sup { font-size: 75%; line-height: 0; position: relative; vertical-align: baseline; }
sup { top: -0.5em; }
sub { bottom: -0.25em; }

ul, ol { margin: 1em 0; padding: 0 0 0 2em; }
/*li p:last-child { margin:0 }*/
li p:last-child { margin:0.8em }
dd { margin: 0 0 0 2em; }

img { border: 0; -ms-interpolation-mode: bicubic; vertical-align: middle; }

table { border-collapse: collapse; border-spacing: 0; }
td { vertical-align: top; }

@media only screen and (min-width: 480px) {
body{font-size:14px;}
}

@media only screen and (min-width: 768px) {
body{font-size:16px;}
}

@media print {
  * { background: transparent !important; color: black !important; filter:none !important; -ms-filter: none !important; }
  body{font-size:12pt; max-width:100%;}
  a, a:visited { text-decoration: underline; }
  hr { height: 1px; border:0; border-bottom:1px solid black; }
  a[href]:after { content: " (" attr(href) ")"; }
  abbr[title]:after { content: " (" attr(title) ")"; }
  .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after { content: ""; }
  pre, blockquote { border: 1px solid #999; padding-right: 1em; page-break-inside: avoid; }
  tr, img { page-break-inside: avoid; }
  img { max-width: 100% !important; }
  @page :left { margin: 15mm 20mm 15mm 10mm; }
  @page :right { margin: 15mm 10mm 15mm 20mm; }
  p, h2, h3 { orphans: 3; widows: 3; }
  h2, h3 { page-break-after: avoid; }
}
</style></head>

<p align=right>【<strong><a href="https://yijunmaverick.github.io/">HOME</a></strong>】<!--&nbsp;&nbsp; 【<strong><a href="https://www.linkedin.com/in/yijun-li-1117a9132/">LINKEDIN</a></strong>】-->
</p>

<hr>
<body marginheight="0"><h1>Selected Publications</h1>
<p><a href="https://scholar.google.com/citations?user=nrsWSt4AAAAJ&hl=en">(Google scholar)</a></p>
<hr>

<!--   
<p><br></p>
-->

<p>
 <img src="quickview/arxiv_motioninversion.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Motion Inversion for Video Customization</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Luozhou Wang, Guibao Shen, Yixun Liang, Xin Tao, Pengfei Wan, Di Zhang, <b>Yijun Li</b>, Ying-Cong Chen</span>
 <br>
    <span class="ban2"> &nbsp; Preprint, 2024</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://wileewang.github.io/MotionInversion/">Project</a>&nbsp; <a href="https://arxiv.org/abs/2403.20193">Paper</a>&nbsp; <a href="https://github.com/EnVision-Research/MotionInversion">Code</a></span>
 <br>
</p>   

<p><br></p>


<p>
 <img src="quickview/arxiv_DandR.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Decompose and Realign: Tackling Condition Misalignment in Text-to-Image Diffusion Models</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Luozhou Wang, Guibao Shen, Wenhang Ge, Guangyong Chen, <b>Yijun Li</b>, Ying-Cong Chen</span>
 <br>
    <span class="ban2"> &nbsp; Preprint, 2023</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://wileewang.github.io/Decompose-and-Realign/">Project</a>&nbsp; <a href="https://arxiv.org/abs/2306.14408">Paper</a>&nbsp; <a href="https://github.com/EnVision-Research/Decompose-and-Realign">Code</a></span>
 <br>
</p>   

<p><br></p>


<p>
 <img src="quickview/arxiv_SepandEnhance.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Separate-and-Enhance: Compositional Finetuning for Text-to-Image Diffusion Models</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Zhipeng Bao, <b>Yijun Li</b>, Krishna Kumar Singh, Yu-Xiong Wang, Martial Hebert</span>
 <br>
    <span class="ban2"> &nbsp; ACM Transactions on Graphics (<b>SIGGRAPH</b>), 2024</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://github.com/zpbao/SepEn">Project</a>&nbsp; <a href="https://camps.aptaracorp.com/ACM_PMS/PMS/ACM/SIGGRAPHCONFERENCEPAPERS24/133/d60517f0-feed-11ee-8182-16bb50361d1f/OUT/siggraphconferencepapers24-133.html">Paper</a></span>
 <br>
</p>   

<p><br></p>


<p>
 <img src="quickview/cvpr_atedm.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">AT-EDM: Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Hongjie Wang, Difan Liu, Yan Kang, <b>Yijun Li</b>, Zhe Lin, Niraj K. Jha, Yuchen Liu</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://atedm.github.io/">Project</a>&nbsp; <a href="https://arxiv.org/abs/2405.05252">Paper</a></span>
 <br>
</p>   

<p><br></p>


<p>
 <img src="quickview/cvpr_magick.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">MAGICK: A Large-scale Captioned Dataset from Matting Generated Images using Chroma Keying</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Ryan D. Burgert, Brian L. Price, Jason Kuen, <b>Yijun Li</b>, Michael S. Ryoo</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://ryanndagreat.github.io/MAGICK/">Project</a>&nbsp; <a href="https://ryanndagreat.github.io/MAGICK/CVPR_Final_No_Appendix.pdf">Paper</a></span>
 <br>
</p>   

<p><br></p>


<p>
 <img src="quickview/wacv_multimodal.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Consistent Multimodal Generation via A Unified GAN Framework</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Zhen Zhu, <b>Yijun Li</b>, Weijie Lyu, Krishna Kumar Singh, Zhixin Shu, Sören Pirk, Derek Hoiem</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2024</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Zhu_Consistent_Multimodal_Generation_via_a_Unified_GAN_Framework_WACV_2024_paper.pdf">Paper</a></span>
 <br>
</p>
    
<p><br></p>

<!-- 
<p>
 <img src="quickview/wacv_p2d2.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">P2D: Plug and Play Discriminator for accelerating GAN frameworks</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Min Jin Chong, Krishna Kumar Singh,  <b>Yijun Li</b>, Jingwan Lu, David Forsyth</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2024</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Chong_P2D_Plug_and_Play_Discriminator_for_Accelerating_GAN_Frameworks_WACV_2024_paper.pdf">Paper</a></span>
 <br>
</p>
    
<p><br></p>
-->

   
<p>
 <img src="quickview/iccv_caricature.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Cross-modal Latent Space Alignment for Image to Avatar Translation</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Manuel Ladron de Guevara, Jose Echevarria, <b>Yijun Li</b>, Yannick Hold-Geoffroy, Cameron Smith, Daichi Ito</span>
 <br>
    <span class="ban2"> &nbsp; IEEE International Conference on Computer Vision (<b>ICCV</b>), 2023</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://www.dropbox.com/scl/fi/ih0hfro5iwsde12jwybqc/ICCV23_manuel_caricature.pdf?rlkey=sqv3j0pwjdl35i94pm56yyzyr&dl=0">Paper</a>&nbsp <a href="https://www.dropbox.com/scl/fi/adx8jcmac88oyna29ja4s/ICCV23_manuel_caricature_supp.pdf?rlkey=0mn83je1cv7anzpjmqv8f2oc8&dl=0">Supplementary</a></span>
 <br>
</p>
    
<p><br></p>


<p>
 <img src="quickview/siggraph_zerop2p.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Zero-shot Image-to-Image Translation</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, <b>Yijun Li</b>, Jingwan Lu, Jun-Yan Zhu</span>
 <br>
    <span class="ban2"> &nbsp; ACM Transactions on Graphics (<b>SIGGRAPH</b>), 2023</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://pix2pixzero.github.io/">Project</a>&nbsp; <a href="https://arxiv.org/abs/2302.03027">Paper</a>&nbsp; <a href="https://github.com/pix2pixzero/pix2pix-zero">Code</a></span>
 <br>
</p>
    
<p><br></p>

<p>
 <img src="quickview/eccv_inpaintingCL.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Contrastive Learning for Diverse Disentangled Foreground Generation</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Yuheng Li, <b>Yijun Li</b>, Jingwan Lu, Eli Shechtman, Yong Jae Lee, Krishna Kumar Singh</span>
 <br>
    <span class="ban2"> &nbsp; European Conference on Computer Vision (<b>ECCV</b>), 2022</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136760313.pdf">Paper</a></span>
 <br>
</p>

<p><br></p>
    
<p>
 <img src="quickview/eccv_3dfmgan.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">3D-FM GAN: Towards 3D-Controllable Face Manipulation</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Yuchen Liu, Zhixin Shu, <b>Yijun Li</b>, Zhe Lin, Richard Zhang, S.Y. Kung</span>
 <br>
    <span class="ban2"> &nbsp; European Conference on Computer Vision (<b>ECCV</b>), 2022</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://lychenyoko.github.io/3D-FM-GAN-Webpage/">Project</a> &nbsp; <a href="https://arxiv.org/abs/2208.11257">Paper</a></span>
 <br>
</p>  
    
<p><br></p>

<!-- 
<p>
 <img src="quickview/siggraph_clip.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">A Fast Text-Driven Approach for Generating Artistic Content</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Marian Lupascu, Ryan Murdock, Ionut Mironica, <b>Yijun Li</b></span>
 <br>
    <span class="ban2"> &nbsp; ACM Transactions on Graphics (<b>SIGGRAPH</b>) Posters, 2022</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://dl.acm.org/doi/10.1145/3532719.3543208">Paper</a>&nbsp; <a href="https://www.youtube.com/watch?v=MpOLYviDFck">Video</a></span>
 <br>
</p>

<p><br></p>
-->

    
<p>
 <img src="quickview/cvpr_ganinversion.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Spatially-Adaptive Multilayer Selection for GAN Inversion and Editing</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Gaurav Parmar, <b>Yijun Li</b>, Jingwan Lu, Richard Zhang, Jun-Yan Zhu, Krishna Kumar Singh</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://www.cs.cmu.edu/~SAMInversion/">Project</a>&nbsp; <a href="https://arxiv.org/abs/2206.08357">Paper</a>&nbsp; <a href="https://github.com/adobe-research/sam_inversion">Code</a></span>
 <br>
</p>

<p><br></p>
    
<p>
 <img src="quickview/iccv_collagegan1.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Collaging Class-specific GANs for Semantic Image Synthesis</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Yuheng Li, <b>Yijun Li</b>, Jingwan Lu, Eli Shechtman, Yong Jae Lee, Krishna Kumar Singh</span>
 <br>
    <span class="ban2"> &nbsp; IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://yuheng-li.github.io/CollageGAN/">Project</a>&nbsp; <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Collaging_Class-Specific_GANs_for_Semantic_Image_Synthesis_ICCV_2021_paper.pdf">Paper</a></span>
 <br>
</p>

<p><br></p>

<p>
 <img src="quickview/ijcv_caricature2.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Learning to Caricature via Semantic Shape Transform</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Wenqing Chu, Wei-Chih Hung, Yi-Hsuan Tsai, Yu-Ting Chang, <b>Yijun Li</b>, Deng Cai, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; International Journal of Computer Vision (<b>IJCV</b>), 2021</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://arxiv.org/abs/2008.05090">Paper</a> &nbsp; <a href="https://github.com/wenqingchu/Semantic-CariGANs">Code</a></span>
 <br>
</p> 
    
<p><br></p>
    
<p>
 <img src="quickview/cvpr_gan2gan.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Few-shot Image Generation via Cross-domain Correspondence</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Utkarsh Ojha, <b>Yijun Li</b>, Jingwan Lu, Alexei A. Efros, Yong Jae Lee, Eli Shechtman, Richard Zhang</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://utkarshojha.github.io/few-shot-gan-adaptation/">Project</a> &nbsp; <a href="https://arxiv.org/abs/2104.06820">Paper</a> &nbsp; <a href="https://github.com/utkarshojha/few-shot-gan-adaptation">Code</a></span>
 <br>
</p> 
    
<p><br></p>
    
<p>
 <img src="quickview/cvpr_swag.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Rethinking and Improving the Robustness of Image Style Transfer</font></span>
 <br>
 <span class="ban2"> &nbsp; <font color="red"><b>Oral</b></font> &nbsp; <a href="http://cvpr2021.thecvf.com/node/290"><font color="blue"><b>Best Paper Candidate</b></font></a></span>
 <br>
 <span class="ban2"> &nbsp; Pei Wang, <b>Yijun Li</b>, Nuno Vasconcelos</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://arxiv.org/abs/2104.05623">Paper</a>&nbsp; <a href="https://github.com/peiwang062/swag">Code</a></span>
 <br>
</p> 

<p><br></p>

<p>
 <img src="quickview/cvpr_imagine.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">IMAGINE: Image Synthesis by Image-Guided Model Inversion</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Pei Wang, <b>Yijun Li</b>, Krishna Kumar Singh, Jingwan Lu, Nuno Vasconcelos</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://arxiv.org/abs/2104.05895">Paper</a></span>
 <br>
</p> 

<p><br></p>
    
<p>
 <img src="quickview/cvpr_gan_compression1.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Content-Aware GAN Compression</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Yuchen Liu, Zhixin Shu, <b>Yijun Li</b>, Zhe Lin, Federico Perazzi, S.Y. Kung</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://lychenyoko.github.io/content_aware_gan_compression/">Project</a> &nbsp; <a href="https://arxiv.org/abs/2104.02244">Paper</a> &nbsp; <a href="https://github.com/lychenyoko/content-aware-gan-compression">Code</a></span>
 <br>
</p>  
    
<p><br></p>
    
<p>
 <img src="quickview/wacv_extrapolation.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Controllable and Progressive Image Extrapolation</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Lu Jiang, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Li_Controllable_and_Progressive_Image_Extrapolation_WACV_2021_paper.pdf">Paper</a></span>
 <br>
</p>    

<p><br></p>
    
<p>
 <img src="quickview/nips_ewc.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Few-shot Image Generation with Elastic Weight Consolidation</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Richard Zhang, Jingwan Lu, Eli Shechtman</span>
 <br>
    <span class="ban2"> &nbsp; Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2020</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://yijunmaverick.github.io/publications/ewc/">Project</a> &nbsp; <a href="https://papers.nips.cc/paper/2020/file/b6d767d2f8ed5d21a44b0e5886680cb9-Paper.pdf">Paper</a> &nbsp; <a href="https://proceedings.neurips.cc/paper/2020/file/b6d767d2f8ed5d21a44b0e5886680cb9-Supplemental.pdf">Supplemental</a></span>
 <br>
</p>    

<p><br></p>

<p>
 <img src="quickview/eccv_artisticflow.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Modeling Artistic Workflows for Image Generation and Editing</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Hung-Yu Tseng, Matthew Fisher, Jingwan Lu, <b>Yijun Li</b>, Vladimir Kim, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; European Conference on Computer Vision (<b>ECCV</b>), 2020</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://arxiv.org/pdf/2007.07238.pdf">Paper</a> &nbsp; <a href="https://github.com/hytseng0509/ArtEditing">Code</a></span>
 <br>
</p>    

<p><br></p>
    
<p>
 <img src="quickview/cvpr_distill.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Collaborative Distillation for Ultra-Resolution Universal Style Transfer</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Huan Wang, <b>Yijun Li</b>, Yuehai Wang, Haoji Hu, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020</span>
 <br>
    <span class="ban2"> &nbsp; <a href="https://arxiv.org/pdf/2003.08436.pdf">Paper</a> &nbsp; <a href="https://github.com/mingsun-tse/collaborative-distillation">Code</a></span>
 <br>
</p>    

<p><br></p>


<p>
 <img src="quickview/wacv_videostyle.gif" height="120" width="250" align="left"><span> &nbsp; <font size="4">Fast Video Multi-Style Transfer</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; Wei Gao, <b>Yijun Li</b>, Yihang Yin, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2020</span>
 <br>
    <span class="ban2"> &nbsp; <a href="http://openaccess.thecvf.com/content_WACV_2020/papers/Gao_Fast_Video_Multi-Style_Transfer_WACV_2020_paper.pdf">Paper</a> &nbsp; <a href="https://github.com/SaberArthurus/Fast-Multi-Video-Style-Transfer">Code</a></span>
 <br>
</p>    

<p><br></p>

    
<p>
 <img src="quickview/cvpr_pencil.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Im2Pencil: Controllable Pencil Illustration from Photographs</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Chen Fang, Aaron Hertzmann, Eli Shechtman, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019</span>
 <br>
 <span class="ban2"> &nbsp; <a href="https://arxiv.org/pdf/1903.08682.pdf">Paper</a> &nbsp; <a href="https://github.com/Yijunmaverick/Im2Pencil">Code</a></span>
 <br>
</p>

<p><br></p>
    
<p>
 <img src="quickview/pami_djf.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Joint Image Filtering with Deep Convolutional Networks</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Jia-Bin Huang, Narendra Ahuja, Ming-Hsuan Yang</span>
 <br>
 <span class="ban2"> &nbsp; IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2018</span>
 <br>
 <span class="ban2"> &nbsp; <a href="https://arxiv.org/pdf/1710.04200.pdf">Paper</a> &nbsp; <a href="https://github.com/Yijunmaverick/DeepJointFilter">Code</a></span>
 <br>
</p>
    
<p><br></p>

<p>
 <img src="quickview/eccv_photowct1.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">A Closed-form Solution to Photorealistic Image Stylization</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Ming-Yu Liu, Xueting Li, Ming-Hsuan Yang, Jan Kautz</span>
 <br>
 <span class="ban2"> &nbsp; European Conference on Computer Vision (<b>ECCV</b>), 2018</span>
 <br>
 <span class="ban2"> &nbsp; <a href="https://arxiv.org/pdf/1802.06474.pdf">Paper</a> &nbsp; <a href="https://github.com/NVIDIA/FastPhotoStyle">Code (<font color="red"><b>11k stars</b></font>)</a></span>
 <br>
</p>

<p><br></p>

<p>
 <img src="quickview/flag.png" height="120" width="125" align="left">
 <img src="quickview/flag_pred16.gif" height="120" width="125" align="left">
 <span> &nbsp; <font size="4">Flow-Grounded Spatial-Temporal Video Prediction from Still Images</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; European Conference on Computer Vision (<b>ECCV</b>), 2018</span>
 <br>
 <span class="ban2"> &nbsp; <a href="https://arxiv.org/pdf/1807.09755.pdf">Paper</a> &nbsp; <a href="https://github.com/Yijunmaverick/FlowGrounded-VideoPrediction">Code</a></span>
 <br>
</p>

<p><br></p>
    
<p>
 <img src="quickview/nips_wct.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Universal Style Transfer via Feature Transforms</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; Advances in Neural Information Processing Systems (<b>NIPS</b>), 2017</span>
 <br>
 <span class="ban2"> &nbsp; <a href="http://papers.nips.cc/paper/6642-universal-style-transfer-via-feature-transforms.pdf">Paper</a> &nbsp; <a href="https://github.com/Yijunmaverick/UniversalStyleTransfer">Code</a> &nbsp; <a href="https://www.youtube.com/watch?v=v1oWke0Qf1E">Two Minute Papers</a></span>
 <br>
</p>
    
<p><br></p>
    
<p>
 <img src="quickview/cvpr_dts.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Diversified Texture Synthesis with Feed-forward Networks</font></span>
 <br>
 <span class="ban2"> &nbsp; <font color="red"><b>Spotlight</b></font></span>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang</span>
 <br>
 <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017</span>
 <br>
 <span class="ban2"> &nbsp; <a href="https://drive.google.com/file/d/1tPYy-cY3-ij3ch3V4LFvv24YoXrmOuTH/view">Paper</a> &nbsp; <a href="https://github.com/Yijunmaverick/MultiTextureSynthesis">Code</a> &nbsp; <a href="https://sites.google.com/site/yijunlimaverick/texture-synthesis">Project</a></span>
 <br>
</p>

<p><br></p>
    
<p>
 <img src="quickview/cvpr_face.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Generative Face Completion</font></span>
 <br>
 <br>
    <span class="ban2"> &nbsp; <b>Yijun Li</b>, Sifei Liu, Jimei Yang, Ming-Hsuan Yang</span>
 <br>
 <span class="ban2"> &nbsp; IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017</span>
 <br>
 <span class="ban2"> &nbsp; <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Generative_Face_Completion_CVPR_2017_paper.pdf">Paper</a> &nbsp; <a href="https://github.com/Yijunmaverick/GenerativeFaceCompletion">Code</a> &nbsp; <a href="https://sites.google.com/site/yijunlimaverick/face-completion">Project</a></span>
 <br>
</p>
 
<p><br></p>
    
<p>
 <img src="quickview/eccv_djf.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Deep Joint Image Filtering</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Jia-Bin Huang, Narendra Ahuja, Ming-Hsuan Yang</span>
 <br>
    <span class="ban2"> &nbsp; European Conference on Computer Vision (<b>ECCV</b>), 2016</span>
 <br>
 <span class="ban2"> &nbsp; <a href="https://drive.google.com/file/d/0B8_MZ8a8aoSeSVZRNVB1TkYtbFU/view">Paper</a> &nbsp; <a href="https://github.com/Yijunmaverick/DeepJointFilter">Code</a> &nbsp; <a href="https://sites.google.com/site/yijunlimaverick/deep-joint-filter">Project</a></span>
 <br>
</p>
    
<p><br></p>
    
<p>
 <img src="quickview/spl_cosaliency.png" height="120" width="250" align="left"><span> &nbsp; <font size="4">Efficient Saliency-Model-Guided Visual Co-Saliency Detection</font></span>
 <br>
 <br>
 <span class="ban2"> &nbsp; <b>Yijun Li</b>, Keren Fu, Zhi Liu, Jie Yang</span>
 <br>
    <span class="ban2"> &nbsp; IEEE Signal Processing Letters (<b>SPL</b>), 2015</span>
 <br>
 <span class="ban2"> &nbsp; <a href="https://drive.google.com/file/d/1ZWxy_d1zZrzjHqxa85mMSaVp5-HI9ANb/view?usp=sharing">Paper</a> &nbsp; <a href="https://drive.google.com/file/d/10yPWyT0n8geysP_nh91TVeobRpzlv98J/view?usp=sharing">Code</a></span>
 <br>
</p>
    
    
    
<p>
<br>
</p>

<hr>
<center> Everything will be OK in the end. If it is not OK, it is not the end.</center></body></html>
